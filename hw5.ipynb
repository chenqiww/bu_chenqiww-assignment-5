{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioLSVYuG__Ut",
        "outputId": "ba179c72-b42f-4fd9-a68a-79e80eb676b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cross-validation results (sorted by ROC AUC):\n",
            "     k distance_metric  weighted  accuracy  precision    recall  f1_score  \\\n",
            "18  30       manhattan      True  0.868534   0.763333  0.507422  0.609478   \n",
            "14  25       manhattan      True  0.869668   0.763243  0.515667  0.615402   \n",
            "22  40       manhattan      True  0.865934   0.763564  0.488958  0.595872   \n",
            "26  50       manhattan      True  0.863201   0.762284  0.470823  0.581820   \n",
            "16  30       euclidean      True  0.866401   0.754448  0.503463  0.603632   \n",
            "10  20       manhattan      True  0.871001   0.760838  0.528196  0.623411   \n",
            "8   20       euclidean      True  0.869001   0.751763  0.526220  0.618928   \n",
            "12  25       euclidean      True  0.865867   0.748679  0.507420  0.604688   \n",
            "15  25       manhattan     False  0.867601   0.759816  0.505444  0.606904   \n",
            "19  30       manhattan     False  0.866934   0.748451  0.515662  0.610492   \n",
            "\n",
            "     roc_auc  \n",
            "18  0.899394  \n",
            "14  0.899230  \n",
            "22  0.898722  \n",
            "26  0.898211  \n",
            "16  0.897019  \n",
            "10  0.897011  \n",
            "8   0.896556  \n",
            "12  0.896540  \n",
            "15  0.896311  \n",
            "19  0.896089  \n",
            "\n",
            "Best hyperparameters: k=30, distance_metric=manhattan, weighted=True\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define the KNN class with probability output\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean', weighted=False):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "        self.weighted = weighted  # Use weighted voting if True\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        proba = []\n",
        "        for x in X:\n",
        "            distances = self.compute_distance(self.X_train, x)\n",
        "            k_indices = distances.argsort()[:self.k]\n",
        "            k_nearest_labels = self.y_train[k_indices]\n",
        "            k_nearest_distances = distances[k_indices]\n",
        "            if self.weighted:\n",
        "                # Weighted probabilities\n",
        "                weights = 1 / (k_nearest_distances + 1e-5)  # Avoid division by zero\n",
        "                prob = np.sum(weights * k_nearest_labels) / np.sum(weights)\n",
        "            else:\n",
        "                # Simple average\n",
        "                prob = np.mean(k_nearest_labels)\n",
        "            proba.append(prob)\n",
        "        return np.array(proba)\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        proba = self.predict_proba(X)\n",
        "        return (proba >= threshold).astype(int)\n",
        "\n",
        "    def compute_distance(self, X, x):\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            distances = np.sqrt(np.sum((X - x) ** 2, axis=1))\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            distances = np.sum(np.abs(X - x), axis=1)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported distance metric\")\n",
        "        return distances\n",
        "\n",
        "# Function to compute ROC AUC manually\n",
        "def compute_roc_auc(y_true, y_scores, num_thresholds=100):\n",
        "    thresholds = np.linspace(0, 1, num_thresholds)\n",
        "    tpr_list = []\n",
        "    fpr_list = []\n",
        "    for thresh in thresholds:\n",
        "        y_pred = (y_scores >= thresh).astype(int)\n",
        "        tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "        tn = np.sum((y_true == 0) & (y_pred == 0))\n",
        "        fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "        fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "\n",
        "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0  # Sensitivity\n",
        "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # 1 - Specificity\n",
        "        tpr_list.append(tpr)\n",
        "        fpr_list.append(fpr)\n",
        "    # Sort false positive rates and true positive rates\n",
        "    fpr_list, tpr_list = zip(*sorted(zip(fpr_list, tpr_list)))\n",
        "    # Compute AUC using the trapezoidal rule\n",
        "    roc_auc = np.trapz(tpr_list, fpr_list)\n",
        "    return roc_auc\n",
        "\n",
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Combine train and test data for consistent preprocessing\n",
        "    data = pd.concat([train_data, test_data], sort=False).reset_index(drop=True)\n",
        "\n",
        "    # Drop unnecessary columns\n",
        "    data.drop(['CustomerId', 'Surname'], axis=1, inplace=True)\n",
        "\n",
        "    # Handle missing values in 'Gender' and 'Geography'\n",
        "    data['Gender'] = data['Gender'].fillna('Unknown')\n",
        "    data['Geography'] = data['Geography'].fillna('Unknown')\n",
        "\n",
        "    # Map 'Gender' values to 0 and 1; handle unknowns\n",
        "    gender_mapping = {'Male': 0, 'Female': 1, 'Unknown': -1}\n",
        "    data['Gender'] = data['Gender'].map(gender_mapping)\n",
        "\n",
        "    # One-hot encode 'Geography' including 'Unknown'\n",
        "    geography_dummies = pd.get_dummies(data['Geography'], prefix='Geography')\n",
        "    data = pd.concat([data, geography_dummies], axis=1)\n",
        "    data.drop('Geography', axis=1, inplace=True)\n",
        "\n",
        "    # Convert geography dummy columns from bool to int\n",
        "    geography_columns = geography_dummies.columns.tolist()\n",
        "    data[geography_columns] = data[geography_columns].astype(int)\n",
        "\n",
        "    # Convert numeric columns to numeric data types\n",
        "    numeric_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
        "                    'EstimatedSalary']\n",
        "    for col in numeric_cols:\n",
        "        if col in data.columns:\n",
        "            data[col] = pd.to_numeric(data[col], errors='coerce')\n",
        "\n",
        "    # Handle missing values in numeric columns\n",
        "    data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())\n",
        "\n",
        "    # Convert boolean columns to integers\n",
        "    boolean_cols = ['HasCrCard', 'IsActiveMember']\n",
        "    for col in boolean_cols:\n",
        "        if col in data.columns:\n",
        "            data[col] = data[col].astype(int)\n",
        "\n",
        "    # Ensure 'Exited' is integer type\n",
        "    if 'Exited' in data.columns:\n",
        "        data['Exited'] = data['Exited'].fillna(0).astype(int)\n",
        "\n",
        "    # Prepare features to scale: select all numeric columns except 'id' and 'Exited'\n",
        "    features_to_scale = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    features_to_scale = [col for col in features_to_scale if col not in ['Exited', 'id']]\n",
        "\n",
        "    # Feature scaling using Min-Max scaling\n",
        "    for feature in features_to_scale:\n",
        "        min_val = data[feature].min()\n",
        "        max_val = data[feature].max()\n",
        "        if max_val - min_val != 0:\n",
        "            data[feature] = (data[feature] - min_val) / (max_val - min_val)\n",
        "        else:\n",
        "            data[feature] = 0  # If no variation, set the feature to zero\n",
        "\n",
        "    # Split data back into train and test sets\n",
        "    train = data[:len(train_data)].reset_index(drop=True)\n",
        "    test = data[len(train_data):].reset_index(drop=True)\n",
        "\n",
        "    X_train = train.drop(['Exited', 'id'], axis=1).values.astype(float)\n",
        "    y_train = train['Exited'].values.astype(int)\n",
        "    X_test = test.drop(['Exited', 'id'], axis=1).values.astype(float)\n",
        "\n",
        "    train_ids = train['id'].values if 'id' in train.columns else None\n",
        "    test_ids = test['id'].values if 'id' in test.columns else None\n",
        "\n",
        "    return X_train, y_train, X_test, train_ids, test_ids\n",
        "\n",
        "# Check for class imbalance\n",
        "def check_class_balance(y):\n",
        "    unique, counts = np.unique(y, return_counts=True)\n",
        "    imbalance_ratio = counts.min() / counts.max()\n",
        "    return imbalance_ratio\n",
        "\n",
        "# Define cross-validation function with ROC AUC\n",
        "def cross_validate(X, y, k_list, distance_metrics, weighted_options, n_splits=5):\n",
        "    results = []\n",
        "    n_samples = len(X)\n",
        "    indices = np.arange(n_samples)\n",
        "\n",
        "    # Stratify the folds based on class labels\n",
        "    class_indices = {}\n",
        "    for idx, label in enumerate(y):\n",
        "        if label not in class_indices:\n",
        "            class_indices[label] = []\n",
        "        class_indices[label].append(idx)\n",
        "\n",
        "    fold_indices = [[] for _ in range(n_splits)]\n",
        "    for label, idx_list in class_indices.items():\n",
        "        np.random.shuffle(idx_list)\n",
        "        folds = np.array_split(idx_list, n_splits)\n",
        "        for i in range(n_splits):\n",
        "            fold_indices[i].extend(folds[i])\n",
        "\n",
        "    for k in k_list:\n",
        "        for metric in distance_metrics:\n",
        "            for weighted in weighted_options:\n",
        "                scores = {'accuracy': [], 'precision': [], 'recall': [], 'f1_score': [], 'roc_auc': []}\n",
        "                for i in range(n_splits):\n",
        "                    valid_idx = fold_indices[i]\n",
        "                    train_idx = np.hstack([fold_indices[j] for j in range(n_splits) if j != i])\n",
        "\n",
        "                    X_train_cv, y_train_cv = X[train_idx], y[train_idx]\n",
        "                    X_valid_cv, y_valid_cv = X[valid_idx], y[valid_idx]\n",
        "\n",
        "                    knn = KNN(k=k, distance_metric=metric, weighted=weighted)\n",
        "                    knn.fit(X_train_cv, y_train_cv)\n",
        "                    y_proba = knn.predict_proba(X_valid_cv)\n",
        "                    y_pred = (y_proba >= 0.5).astype(int)\n",
        "\n",
        "                    # Compute metrics manually\n",
        "                    tp = np.sum((y_valid_cv == 1) & (y_pred == 1))\n",
        "                    tn = np.sum((y_valid_cv == 0) & (y_pred == 0))\n",
        "                    fp = np.sum((y_valid_cv == 0) & (y_pred == 1))\n",
        "                    fn = np.sum((y_valid_cv == 1) & (y_pred == 0))\n",
        "\n",
        "                    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "                    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "                    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "                    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "                    # Compute ROC AUC manually\n",
        "                    roc_auc = compute_roc_auc(y_valid_cv, y_proba)\n",
        "\n",
        "                    scores['accuracy'].append(accuracy)\n",
        "                    scores['precision'].append(precision)\n",
        "                    scores['recall'].append(recall)\n",
        "                    scores['f1_score'].append(f1)\n",
        "                    scores['roc_auc'].append(roc_auc)\n",
        "                avg_scores = {metric_name: np.mean(scores[metric_name]) for metric_name in scores}\n",
        "                results.append({\n",
        "                    'k': k,\n",
        "                    'distance_metric': metric,\n",
        "                    'weighted': weighted,\n",
        "                    **avg_scores\n",
        "                })\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Load and preprocess data\n",
        "X, y, X_test, train_ids, test_ids = preprocess_data('train.csv', 'test.csv')\n",
        "\n",
        "# Check class balance\n",
        "imbalance_ratio = check_class_balance(y)\n",
        "\n",
        "# Hyperparameter tuning\n",
        "k_list = [3, 10, 20, 25, 30, 40, 50]\n",
        "distance_metrics = ['euclidean', 'manhattan']\n",
        "weighted_options = [True, False]\n",
        "cv_results = cross_validate(X, y, k_list, distance_metrics, weighted_options, n_splits=5)\n",
        "\n",
        "# Now sort by 'roc_auc' instead of 'f1_score'\n",
        "print(\"\\nCross-validation results (sorted by ROC AUC):\")\n",
        "print(cv_results.sort_values(by='roc_auc', ascending=False).head(10))\n",
        "\n",
        "# Select the best hyperparameters based on highest ROC AUC\n",
        "best_result = cv_results.sort_values(by='roc_auc', ascending=False).iloc[0]\n",
        "best_k = best_result['k']\n",
        "best_metric = best_result['distance_metric']\n",
        "best_weighted = best_result['weighted']\n",
        "print(f\"\\nBest hyperparameters: k={best_k}, distance_metric={best_metric}, weighted={best_weighted}\")\n",
        "\n",
        "# Train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "knn = KNN(k=int(best_k), distance_metric=best_metric, weighted=best_weighted)\n",
        "knn.fit(X, y)\n",
        "test_proba = knn.predict_proba(X_test)\n",
        "\n",
        "# Save test predictions (probabilities)\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_ids,\n",
        "    'Exited': test_proba  # Use probabilities instead of class labels\n",
        "})\n",
        "submission.to_csv('submissions.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "buKEMOLYAKfv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}